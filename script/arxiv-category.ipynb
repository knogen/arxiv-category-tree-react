{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /home/ider/miniconda3/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: requests in /home/ider/miniconda3/lib/python3.8/site-packages (2.22.0)\n",
      "Requirement already satisfied: pandas in /home/ider/miniconda3/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: lxml in /home/ider/miniconda3/lib/python3.8/site-packages (5.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ider/miniconda3/lib/python3.8/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ider/miniconda3/lib/python3.8/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ider/miniconda3/lib/python3.8/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ider/miniconda3/lib/python3.8/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ider/miniconda3/lib/python3.8/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ider/miniconda3/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/ider/miniconda3/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ider/miniconda3/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ider/miniconda3/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ider/miniconda3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ider/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install  bs4 requests pandas lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-229c4199f69e>:11: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(response, 'lxml')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_taxanomy() -> dict:\n",
    "    \"\"\" load ArXiv taxonomy from https://arxiv.org/category_taxonomy\n",
    "\n",
    "    :return: groups, archives and categories\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get('https://arxiv.org/category_taxonomy').text\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "    root = soup.find('div', {'id': 'category_taxonomy_list'})\n",
    "    tags = root.find_all([\"h2\", \"h3\", \"h4\", \"p\"], recursive=True)\n",
    "\n",
    "    level_1_name = \"\"\n",
    "    level_2_code = \"\"\n",
    "    level_2_name = \"\"\n",
    "\n",
    "    level_1_names = []\n",
    "    level_2_codes = []\n",
    "    level_2_names = []\n",
    "    level_3_codes = []\n",
    "    level_3_names = []\n",
    "    level_3_notes = []\n",
    "\n",
    "    for tag in tags:\n",
    "        if tag.name == \"h2\":\n",
    "            level_1_name = tag.text\n",
    "            level_2_code = tag.text\n",
    "            level_2_name = tag.text\n",
    "        elif tag.name == \"h3\":\n",
    "            raw = tag.text\n",
    "            level_2_code = re.sub(r\"(.*)\\((.*)\\)\", r\"\\2\", raw)\n",
    "            level_2_name = re.sub(r\"(.*)\\((.*)\\)\", r\"\\1\", raw)\n",
    "        elif tag.name == \"h4\":\n",
    "            raw = tag.text\n",
    "            level_3_code = re.sub(r\"(.*) \\((.*)\\)\", r\"\\1\", raw)\n",
    "            level_3_name = re.sub(r\"(.*) \\((.*)\\)\", r\"\\2\", raw)\n",
    "        elif tag.name == \"p\":\n",
    "            notes = tag.text\n",
    "            level_1_names.append(level_1_name)\n",
    "            level_2_names.append(level_2_name)\n",
    "            level_2_codes.append(level_2_code)\n",
    "            level_3_names.append(level_3_name)\n",
    "            level_3_codes.append(level_3_code)\n",
    "            level_3_notes.append(notes)\n",
    "\n",
    "    groups = []  # {name}\n",
    "    archives = []  # {name, id, inGroup}\n",
    "    categories = []  # {name, id, description, inArchive}\n",
    "\n",
    "    group_names = list(set(level_1_names))\n",
    "    for name in group_names:\n",
    "        groups.append({\"name\": name})\n",
    "\n",
    "    df_archives = pd.DataFrame({\n",
    "        'inGroup': level_1_names,\n",
    "        'name': level_2_names,\n",
    "        'id': level_2_codes\n",
    "\n",
    "    })\n",
    "    df_archives.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    archives = df_archives.to_dict(orient=\"records\")\n",
    "\n",
    "    df_categories = pd.DataFrame({\n",
    "        'inArchive': level_2_names,\n",
    "        'name': level_3_names,\n",
    "        'id': level_3_codes,\n",
    "        'description': level_3_notes\n",
    "    })\n",
    "    df_categories.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    categories = df_categories.to_dict(orient=\"records\")\n",
    "\n",
    "    return {\"groups\": groups, \"archives\": archives, \"categories\": categories}\n",
    "\n",
    "data = load_taxanomy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data example\n",
    "\n",
    "```\n",
    "  {\n",
    "    title: 'parent 1',\n",
    "    key: '0-0',\n",
    "    children: [\n",
    "      {\n",
    "        title: 'parent 1-0',\n",
    "        key: '0-0-0',\n",
    "        children: [\n",
    "          {\n",
    "            title: 'leaf',\n",
    "            key: '0-0-0-0',\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "tree_group_archive = collections.defaultdict(list)\n",
    "for item in data[\"archives\"]:\n",
    "    tree_group_archive[item['inGroup']].append(item)\n",
    "    \n",
    "    \n",
    "tree_archive_category = collections.defaultdict(list)\n",
    "for item in data[\"categories\"]:\n",
    "    tree_archive_category[item['inArchive']].append(item)\n",
    "\n",
    "tree_index = 0\n",
    "\n",
    "tree_data_dict = {}\n",
    "# build tree_group_archive\n",
    "for group_name, archive_item_list in tree_group_archive.items():\n",
    "    if group_name not in tree_data_dict:\n",
    "        tree_data_dict[group_name] = {\n",
    "            'title': group_name,\n",
    "            'children': [],\n",
    "            'key': str(tree_index),\n",
    "            'level': 0,\n",
    "        }\n",
    "        tree_index+=1\n",
    "        \n",
    "    for archive_item in archive_item_list:\n",
    "        \n",
    "        archive_title = archive_item['name']\n",
    "        \n",
    "        archive_children = []\n",
    "        for category_item in tree_archive_category[archive_item['name']]:\n",
    "            archive_children.append({\n",
    "                'title': category_item['name'],\n",
    "                'id': category_item['id'],\n",
    "                'description': category_item['description'],\n",
    "                'key': str(tree_index),\n",
    "                'isLeaf': True,\n",
    "                'level': 2,\n",
    "            })\n",
    "            tree_index+=1\n",
    "    \n",
    "        tree_data_dict[group_name]['children'].append({\n",
    "            'title': archive_title,\n",
    "            'id': archive_item['id'],\n",
    "            'children': archive_children,\n",
    "            'key': str(tree_index),\n",
    "            'level': 1,\n",
    "        })\n",
    "        tree_index+=1\n",
    "    \n",
    "\n",
    "\n",
    "import json\n",
    "with open(\"../app/tree_data.json\", \"w\") as f:\n",
    "    json.dump(list(tree_data_dict.values()),f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
